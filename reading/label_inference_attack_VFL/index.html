<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Label Inference Attacks Against Vertical Federated Learning | Chengyu Zhang</title>
<meta name="keywords" content="Federated Learning, Vertical Federated Learning, Label Inference Attack">
<meta name="description" content="Evaluates privacy risks of vertical federated learning (VFL) and proposes label inference attacks with outstanding performance, highlighting vulnerabilities and defense limitations.">
<meta name="author" content="Chengyu Zhang">
<link rel="canonical" href="https://gnehcuyz.github.io/reading/label_inference_attack_VFL/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.f49d66caae9ea0fd43f21f29e71a8d3e284517ed770f2aa86fa012953ad3c9ef.css" integrity="sha256-9J1myq6eoP1D8h8p5xqNPihFF&#43;13Dyqob6ASlTrTye8=" rel="preload stylesheet" as="style">

    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css" integrity="sha384-n8MVd4RsNIU0tAv4ct0nTaAbDJwPJzDEaqSD1odI+WdtXRGWt2kTvGFasHpSy3SV" crossorigin="anonymous">
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js" integrity="sha384-XjKyOOlGwcjNTAIQHIpgOno0Hl1YQqzUOEleOLALmuqehneUG+vnGctmUb0ZY0l8" crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js" integrity="sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05" crossorigin="anonymous"></script>
<script>
  document.addEventListener("DOMContentLoaded", function() {
    renderMathInElement(document.body, {
      delimiters: [
        {left: '\\[', right: '\\]', display: true},   
        {left: '$$', right: '$$', display: true},     
        {left: '\\(', right: '\\)', display: false},  
      ],
      throwOnError : false
    });
  });
</script>
  
<link rel="icon" href="https://gnehcuyz.github.io/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://gnehcuyz.github.io/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://gnehcuyz.github.io/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://gnehcuyz.github.io/apple-touch-icon.png">
<link rel="mask-icon" href="https://gnehcuyz.github.io/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="https://gnehcuyz.github.io/reading/label_inference_attack_VFL/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript><meta property="og:url" content="https://gnehcuyz.github.io/reading/label_inference_attack_VFL/">
  <meta property="og:site_name" content="Chengyu Zhang">
  <meta property="og:title" content="Label Inference Attacks Against Vertical Federated Learning">
  <meta property="og:description" content="Evaluates privacy risks of vertical federated learning (VFL) and proposes label inference attacks with outstanding performance, highlighting vulnerabilities and defense limitations.">
  <meta property="og:locale" content="en-us">
  <meta property="og:type" content="article">
    <meta property="article:section" content="reading">
    <meta property="article:published_time" content="2024-09-16T00:00:00+00:00">
    <meta property="article:modified_time" content="2024-09-16T00:00:00+00:00">
    <meta property="article:tag" content="Federated Learning">
    <meta property="article:tag" content="Vertical Federated Learning">
    <meta property="article:tag" content="Label Inference Attack">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Label Inference Attacks Against Vertical Federated Learning">
<meta name="twitter:description" content="Evaluates privacy risks of vertical federated learning (VFL) and proposes label inference attacks with outstanding performance, highlighting vulnerabilities and defense limitations.">


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Reading",
      "item": "https://gnehcuyz.github.io/reading/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "Label Inference Attacks Against Vertical Federated Learning",
      "item": "https://gnehcuyz.github.io/reading/label_inference_attack_VFL/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Label Inference Attacks Against Vertical Federated Learning",
  "name": "Label Inference Attacks Against Vertical Federated Learning",
  "description": "Evaluates privacy risks of vertical federated learning (VFL) and proposes label inference attacks with outstanding performance, highlighting vulnerabilities and defense limitations.",
  "keywords": [
    "Federated Learning", "Vertical Federated Learning", "Label Inference Attack"
  ],
  "articleBody": "Introduction Focus: Privacy risks in Vertical Federated Learning (VFL), a framework enabling multi-party collaboration without sharing raw data. Problem: Adversaries can exploit VFL’s structure to infer sensitive label information. Key Insight: Gradients and bottom model vulnerabilities allow label inference. Contributions Introduced three types of label inference attacks (direct, passive, active). Demonstrated attack feasibility across multiple datasets and scenarios. Evaluated potential defenses and highlighted their limitations. Shared insights into VFL vulnerabilities and proposed future research directions. Methodology Passive Label Inference Attack: Exploits bottom model representations with a small labeled dataset to infer labels. Active Label Inference Attack: Enhances attack performance by manipulating the federated model to rely on adversary data. Direct Label Inference Attack: Analyzes gradients to infer labels directly (limited to training data). Results High inference accuracy on various datasets (e.g., CIFAR-10, CIFAR-100, BHI). Active attacks outperformed passive ones by boosting bottom model expressiveness. Defenses like noisy gradients and gradient compression showed limited effectiveness. Discussion Defenses Evaluated: Noisy Gradients Gradient Compression Privacy-Preserving Deep Learning DiscreteSGD (a modified SignSGD) Findings: Existing defenses mitigate only some attack types and often degrade model performance. Calls for novel defense strategies tailored to VFL. Future Work Expand evaluations to other ML models and architectures (e.g., logistic regression, gradient boosting trees). Investigate additional privacy risks in VFL and design robust defense mechanisms. Conclusion This work sheds light on inherent privacy risks in VFL, proposing effective attacks and emphasizing the urgency of developing tailored defenses to protect sensitive data.\nReference Fu, C., Zhang, X., Ji, S., et al. (2022). Label Inference Attacks Against Vertical Federated Learning. Proceedings of the 31st USENIX Security Symposium. Link to paper ",
  "wordCount" : "269",
  "inLanguage": "en",
  "datePublished": "2024-09-16T00:00:00Z",
  "dateModified": "2024-09-16T00:00:00Z",
  "author":{
    "@type": "Person",
    "name": "Chengyu Zhang"
  },
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://gnehcuyz.github.io/reading/label_inference_attack_VFL/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Chengyu Zhang",
    "logo": {
      "@type": "ImageObject",
      "url": "https://gnehcuyz.github.io/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://gnehcuyz.github.io/" accesskey="h" title="Chengyu Zhang (Alt + H)">Chengyu Zhang</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)" aria-label="Toggle theme">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://gnehcuyz.github.io/about/" title="About me">
                    <span>About me</span>
                </a>
            </li>
            <li>
                <a href="https://gnehcuyz.github.io/experience" title="Experience">
                    <span>Experience</span>
                </a>
            </li>
            <li>
                <a href="https://gnehcuyz.github.io/research/" title="Research">
                    <span>Research</span>
                </a>
            </li>
            <li>
                <a href="https://gnehcuyz.github.io/publications/" title="Publications">
                    <span>Publications</span>
                </a>
            </li>
            <li>
                <a href="https://gnehcuyz.github.io/projects/" title="Projects">
                    <span>Projects</span>
                </a>
            </li>
            <li>
                <a href="https://gnehcuyz.github.io/posts/" title="Blog">
                    <span>Blog</span>
                </a>
            </li>
            <li>
                <a href="https://gnehcuyz.github.io/tags/" title="Tags">
                    <span>Tags</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    <div class="breadcrumbs"><a href="https://gnehcuyz.github.io/">Home</a>&nbsp;»&nbsp;<a href="https://gnehcuyz.github.io/reading/">Reading</a></div>
    <h1 class="post-title entry-hint-parent">
      Label Inference Attacks Against Vertical Federated Learning
    </h1>
    <div class="post-meta"><span title='2024-09-16 00:00:00 +0000 UTC'>September 16, 2024</span>&nbsp;·&nbsp;2 min&nbsp;·&nbsp;Chengyu Zhang

</div>
  </header> <div class="toc">
    <details >
        <summary accesskey="c" title="(Alt + C)">
            <span class="details">Table of Contents</span>
        </summary>

        <div class="inner"><ul>
                <li>
                    <a href="#introduction" aria-label="Introduction">Introduction</a></li>
                <li>
                    <a href="#contributions" aria-label="Contributions">Contributions</a></li>
                <li>
                    <a href="#methodology" aria-label="Methodology">Methodology</a></li>
                <li>
                    <a href="#results" aria-label="Results">Results</a></li>
                <li>
                    <a href="#discussion" aria-label="Discussion">Discussion</a></li>
                <li>
                    <a href="#future-work" aria-label="Future Work">Future Work</a></li>
                <li>
                    <a href="#conclusion" aria-label="Conclusion">Conclusion</a></li>
                <li>
                    <a href="#reference" aria-label="Reference">Reference</a>
                </li>
            </ul>
        </div>
    </details>
</div>

  <div class="post-content"><h1 id="introduction">Introduction<a hidden class="anchor" aria-hidden="true" href="#introduction">#</a></h1>
<ul>
<li><strong>Focus</strong>: Privacy risks in Vertical Federated Learning (VFL), a framework enabling multi-party collaboration without sharing raw data.</li>
<li><strong>Problem</strong>: Adversaries can exploit VFL&rsquo;s structure to infer sensitive label information.</li>
<li><strong>Key Insight</strong>: Gradients and bottom model vulnerabilities allow label inference.</li>
</ul>
<h1 id="contributions">Contributions<a hidden class="anchor" aria-hidden="true" href="#contributions">#</a></h1>
<ol>
<li>Introduced three types of label inference attacks (direct, passive, active).</li>
<li>Demonstrated attack feasibility across multiple datasets and scenarios.</li>
<li>Evaluated potential defenses and highlighted their limitations.</li>
<li>Shared insights into VFL vulnerabilities and proposed future research directions.</li>
</ol>
<h1 id="methodology">Methodology<a hidden class="anchor" aria-hidden="true" href="#methodology">#</a></h1>
<ul>
<li><strong>Passive Label Inference Attack</strong>: Exploits bottom model representations with a small labeled dataset to infer labels.</li>
<li><strong>Active Label Inference Attack</strong>: Enhances attack performance by manipulating the federated model to rely on adversary data.</li>
<li><strong>Direct Label Inference Attack</strong>: Analyzes gradients to infer labels directly (limited to training data).</li>
</ul>
<h1 id="results">Results<a hidden class="anchor" aria-hidden="true" href="#results">#</a></h1>
<ul>
<li>High inference accuracy on various datasets (e.g., CIFAR-10, CIFAR-100, BHI).</li>
<li>Active attacks outperformed passive ones by boosting bottom model expressiveness.</li>
<li>Defenses like noisy gradients and gradient compression showed limited effectiveness.</li>
</ul>
<h1 id="discussion">Discussion<a hidden class="anchor" aria-hidden="true" href="#discussion">#</a></h1>
<ul>
<li><strong>Defenses Evaluated</strong>:
<ul>
<li>Noisy Gradients</li>
<li>Gradient Compression</li>
<li>Privacy-Preserving Deep Learning</li>
<li>DiscreteSGD (a modified SignSGD)</li>
</ul>
</li>
<li><strong>Findings</strong>:
<ul>
<li>Existing defenses mitigate only some attack types and often degrade model performance.</li>
<li>Calls for novel defense strategies tailored to VFL.</li>
</ul>
</li>
</ul>
<h1 id="future-work">Future Work<a hidden class="anchor" aria-hidden="true" href="#future-work">#</a></h1>
<ul>
<li>Expand evaluations to other ML models and architectures (e.g., logistic regression, gradient boosting trees).</li>
<li>Investigate additional privacy risks in VFL and design robust defense mechanisms.</li>
</ul>
<h1 id="conclusion">Conclusion<a hidden class="anchor" aria-hidden="true" href="#conclusion">#</a></h1>
<p>This work sheds light on inherent privacy risks in VFL, proposing effective attacks and emphasizing the urgency of developing tailored defenses to protect sensitive data.</p>
<h1 id="reference">Reference<a hidden class="anchor" aria-hidden="true" href="#reference">#</a></h1>
<ul>
<li>Fu, C., Zhang, X., Ji, S., et al. (2022). <em>Label Inference Attacks Against Vertical Federated Learning</em>. Proceedings of the 31st USENIX Security Symposium. <a href="https://www.usenix.org/conference/usenixsecurity22/presentation/fu-chong">Link to paper</a></li>
</ul>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="https://gnehcuyz.github.io/tags/Federated-Learning/">Federated Learning</a></li>
      <li><a href="https://gnehcuyz.github.io/tags/Vertical-Federated-Learning/">Vertical Federated Learning</a></li>
      <li><a href="https://gnehcuyz.github.io/tags/Label-Inference-Attack/">Label Inference Attack</a></li>
    </ul>
  </footer>
</article>
    </main>
    <footer style="text-align: center; padding: 1rem 0; font-size: 0.9rem;">
    <p>
        Last updated on 2025-05-28 ||
        &copy; 2025 
        <a href="https://yourwebsite.com" style="text-decoration: underline;">Chengyu Zhang</a> ||
        Powered by 
        <a href="https://gohugo.io/" style="text-decoration: underline;">Hugo</a> & 
        <a href="https://themes.gohugo.io/themes/hugo-papermod/" style="text-decoration: underline;">PaperMod</a>
    </p>
</footer>
</body>

</html>
