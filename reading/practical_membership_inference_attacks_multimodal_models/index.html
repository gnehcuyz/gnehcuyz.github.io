<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Practical Membership Inference Attacks Against Large-Scale Multi-Modal Models - A Pilot Study | Chengyu Zhang</title>
<meta name="keywords" content="Membership Inference Attack, Multi-Modal Model">
<meta name="description" content="An investigation of membership inference attacks (MIAs) targeting large-scale multi-modal models like CLIP, introducing practical attack strategies without shadow training.">
<meta name="author" content="Chengyu Zhang">
<link rel="canonical" href="https://gnehcuyz.github.io/reading/practical_membership_inference_attacks_multimodal_models/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.f49d66caae9ea0fd43f21f29e71a8d3e284517ed770f2aa86fa012953ad3c9ef.css" integrity="sha256-9J1myq6eoP1D8h8p5xqNPihFF&#43;13Dyqob6ASlTrTye8=" rel="preload stylesheet" as="style">

    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css" integrity="sha384-n8MVd4RsNIU0tAv4ct0nTaAbDJwPJzDEaqSD1odI+WdtXRGWt2kTvGFasHpSy3SV" crossorigin="anonymous">
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js" integrity="sha384-XjKyOOlGwcjNTAIQHIpgOno0Hl1YQqzUOEleOLALmuqehneUG+vnGctmUb0ZY0l8" crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js" integrity="sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05" crossorigin="anonymous"></script>
<script>
  document.addEventListener("DOMContentLoaded", function() {
    renderMathInElement(document.body, {
      delimiters: [
        {left: '\\[', right: '\\]', display: true},   
        {left: '$$', right: '$$', display: true},     
        {left: '\\(', right: '\\)', display: false},  
      ],
      throwOnError : false
    });
  });
</script>
  
<link rel="icon" href="https://gnehcuyz.github.io/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://gnehcuyz.github.io/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://gnehcuyz.github.io/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://gnehcuyz.github.io/apple-touch-icon.png">
<link rel="mask-icon" href="https://gnehcuyz.github.io/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="https://gnehcuyz.github.io/reading/practical_membership_inference_attacks_multimodal_models/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript><meta property="og:url" content="https://gnehcuyz.github.io/reading/practical_membership_inference_attacks_multimodal_models/">
  <meta property="og:site_name" content="Chengyu Zhang">
  <meta property="og:title" content="Practical Membership Inference Attacks Against Large-Scale Multi-Modal Models - A Pilot Study">
  <meta property="og:description" content="An investigation of membership inference attacks (MIAs) targeting large-scale multi-modal models like CLIP, introducing practical attack strategies without shadow training.">
  <meta property="og:locale" content="en-us">
  <meta property="og:type" content="article">
    <meta property="article:section" content="reading">
    <meta property="article:published_time" content="2024-01-24T00:00:00+00:00">
    <meta property="article:modified_time" content="2024-01-24T00:00:00+00:00">
    <meta property="article:tag" content="Membership Inference Attack">
    <meta property="article:tag" content="Multi-Modal Model">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Practical Membership Inference Attacks Against Large-Scale Multi-Modal Models - A Pilot Study">
<meta name="twitter:description" content="An investigation of membership inference attacks (MIAs) targeting large-scale multi-modal models like CLIP, introducing practical attack strategies without shadow training.">


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Reading",
      "item": "https://gnehcuyz.github.io/reading/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "Practical Membership Inference Attacks Against Large-Scale Multi-Modal Models - A Pilot Study",
      "item": "https://gnehcuyz.github.io/reading/practical_membership_inference_attacks_multimodal_models/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Practical Membership Inference Attacks Against Large-Scale Multi-Modal Models - A Pilot Study",
  "name": "Practical Membership Inference Attacks Against Large-Scale Multi-Modal Models - A Pilot Study",
  "description": "An investigation of membership inference attacks (MIAs) targeting large-scale multi-modal models like CLIP, introducing practical attack strategies without shadow training.",
  "keywords": [
    "Membership Inference Attack", "Multi-Modal Model"
  ],
  "articleBody": "Overview This paper explores privacy risks in large-scale multi-modal models, such as CLIP, focusing on Membership Inference Attacks (MIAs). These attacks identify whether a data point was used in model training, revealing potential privacy vulnerabilities. The study develops practical strategies to perform MIAs without shadow training, addressing computational challenges in large-scale models.\nContributions The study introduces three key MIA strategies:\nCosine Similarity Attack (CSA): A baseline method using cosine similarity between image and text features. Augmentation-Enhanced Attack (AEA): Improves CSA by aggregating cosine similarity changes across data transformations. Weakly Supervised Attack (WSA): Leverages non-member data (e.g., data created after the model’s training) to enhance attack accuracy. Methodology Cosine Similarity Attack (CSA) This attack predicts membership based on cosine similarity scores, which are higher for training data due to the model’s optimization during training.\nAugmentation-Enhanced Attack (AEA) Enhances CSA by applying transformations (e.g., cropping, rotation) to inputs and measuring the resulting changes in cosine similarity. Members exhibit larger decreases in similarity than non-members.\nWeakly Supervised Attack (WSA) Uses a set of guaranteed non-members (e.g., data from after the model’s publication) to estimate membership distributions. This method identifies “pseudo-members” and trains an attack model for improved inference accuracy.\nExperimental Findings Datasets: Experiments used datasets like LAION, CC12M, and MSCOCO, combining large-scale web-scraped data for evaluation. Performance: WSA showed the best results, improving membership accuracy by 17% over CSA and achieving seven times better accuracy at low false-positive rates. Insights: Multi-modal models are more vulnerable to MIAs than previously assumed, with larger models (e.g., ViT-L/14) exhibiting more significant privacy risks. Implications The findings highlight the need for privacy-preserving measures in large-scale multi-modal models. Future research directions include:\nDeveloping efficient privacy defenses for multi-modal systems. Extending the proposed attacks to other foundational models like GPT-3 and BERT. Reference Ko, M., Jin, M., Wang, C., \u0026 Jia, R. (2023). Practical Membership Inference Attacks Against Large-Scale Multi-Modal Models: A Pilot Study. Read the full paper.\n",
  "wordCount" : "319",
  "inLanguage": "en",
  "datePublished": "2024-01-24T00:00:00Z",
  "dateModified": "2024-01-24T00:00:00Z",
  "author":{
    "@type": "Person",
    "name": "Chengyu Zhang"
  },
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://gnehcuyz.github.io/reading/practical_membership_inference_attacks_multimodal_models/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Chengyu Zhang",
    "logo": {
      "@type": "ImageObject",
      "url": "https://gnehcuyz.github.io/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://gnehcuyz.github.io/" accesskey="h" title="Chengyu Zhang (Alt + H)">Chengyu Zhang</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)" aria-label="Toggle theme">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://gnehcuyz.github.io/about/" title="About me">
                    <span>About me</span>
                </a>
            </li>
            <li>
                <a href="https://gnehcuyz.github.io/research/" title="Research">
                    <span>Research</span>
                </a>
            </li>
            <li>
                <a href="https://gnehcuyz.github.io/publications/" title="Publications">
                    <span>Publications</span>
                </a>
            </li>
            <li>
                <a href="https://gnehcuyz.github.io/experience" title="Experience">
                    <span>Experience</span>
                </a>
            </li>
            <li>
                <a href="https://gnehcuyz.github.io/projects/" title="Projects">
                    <span>Projects</span>
                </a>
            </li>
            <li>
                <a href="https://gnehcuyz.github.io/tags/" title="Tags">
                    <span>Tags</span>
                </a>
            </li>
            <li>
                <a href="https://gnehcuyz.github.io/posts/" title="Blog">
                    <span>Blog</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    <div class="breadcrumbs"><a href="https://gnehcuyz.github.io/">Home</a>&nbsp;»&nbsp;<a href="https://gnehcuyz.github.io/reading/">Reading</a></div>
    <h1 class="post-title entry-hint-parent">
      Practical Membership Inference Attacks Against Large-Scale Multi-Modal Models - A Pilot Study
    </h1>
    <div class="post-meta"><span title='2024-01-24 00:00:00 +0000 UTC'>January 24, 2024</span>&nbsp;·&nbsp;2 min&nbsp;·&nbsp;Chengyu Zhang

</div>
  </header> 
  <div class="post-content"><h3 id="overview">Overview<a hidden class="anchor" aria-hidden="true" href="#overview">#</a></h3>
<p>This paper explores privacy risks in large-scale multi-modal models, such as CLIP, focusing on Membership Inference Attacks (MIAs). These attacks identify whether a data point was used in model training, revealing potential privacy vulnerabilities. The study develops practical strategies to perform MIAs without shadow training, addressing computational challenges in large-scale models.</p>
<h3 id="contributions">Contributions<a hidden class="anchor" aria-hidden="true" href="#contributions">#</a></h3>
<p>The study introduces three key MIA strategies:</p>
<ol>
<li><strong>Cosine Similarity Attack (CSA):</strong> A baseline method using cosine similarity between image and text features.</li>
<li><strong>Augmentation-Enhanced Attack (AEA):</strong> Improves CSA by aggregating cosine similarity changes across data transformations.</li>
<li><strong>Weakly Supervised Attack (WSA):</strong> Leverages non-member data (e.g., data created after the model&rsquo;s training) to enhance attack accuracy.</li>
</ol>
<h3 id="methodology">Methodology<a hidden class="anchor" aria-hidden="true" href="#methodology">#</a></h3>
<h4 id="cosine-similarity-attack-csa">Cosine Similarity Attack (CSA)<a hidden class="anchor" aria-hidden="true" href="#cosine-similarity-attack-csa">#</a></h4>
<p>This attack predicts membership based on cosine similarity scores, which are higher for training data due to the model&rsquo;s optimization during training.</p>
<h4 id="augmentation-enhanced-attack-aea">Augmentation-Enhanced Attack (AEA)<a hidden class="anchor" aria-hidden="true" href="#augmentation-enhanced-attack-aea">#</a></h4>
<p>Enhances CSA by applying transformations (e.g., cropping, rotation) to inputs and measuring the resulting changes in cosine similarity. Members exhibit larger decreases in similarity than non-members.</p>
<h4 id="weakly-supervised-attack-wsa">Weakly Supervised Attack (WSA)<a hidden class="anchor" aria-hidden="true" href="#weakly-supervised-attack-wsa">#</a></h4>
<p>Uses a set of guaranteed non-members (e.g., data from after the model’s publication) to estimate membership distributions. This method identifies &ldquo;pseudo-members&rdquo; and trains an attack model for improved inference accuracy.</p>
<h3 id="experimental-findings">Experimental Findings<a hidden class="anchor" aria-hidden="true" href="#experimental-findings">#</a></h3>
<ul>
<li><strong>Datasets:</strong> Experiments used datasets like LAION, CC12M, and MSCOCO, combining large-scale web-scraped data for evaluation.</li>
<li><strong>Performance:</strong> WSA showed the best results, improving membership accuracy by 17% over CSA and achieving seven times better accuracy at low false-positive rates.</li>
<li><strong>Insights:</strong> Multi-modal models are more vulnerable to MIAs than previously assumed, with larger models (e.g., ViT-L/14) exhibiting more significant privacy risks.</li>
</ul>
<h3 id="implications">Implications<a hidden class="anchor" aria-hidden="true" href="#implications">#</a></h3>
<p>The findings highlight the need for privacy-preserving measures in large-scale multi-modal models. Future research directions include:</p>
<ul>
<li>Developing efficient privacy defenses for multi-modal systems.</li>
<li>Extending the proposed attacks to other foundational models like GPT-3 and BERT.</li>
</ul>
<hr>
<h3 id="reference">Reference<a hidden class="anchor" aria-hidden="true" href="#reference">#</a></h3>
<p>Ko, M., Jin, M., Wang, C., &amp; Jia, R. (2023). Practical Membership Inference Attacks Against Large-Scale Multi-Modal Models: A Pilot Study. <a href="https://arxiv.org/abs/2310.00108">Read the full paper</a>.</p>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="https://gnehcuyz.github.io/tags/Membership-Inference-Attack/">Membership Inference Attack</a></li>
      <li><a href="https://gnehcuyz.github.io/tags/Multi-Modal-Model/">Multi-Modal Model</a></li>
    </ul>
  </footer>
</article>
    </main>
    <footer style="text-align: center; padding: 1rem 0; font-size: 0.9rem;">
    <p>
        Last updated on 2025-06-23 ||
        &copy; 2025 
        <a href="https://yourwebsite.com" style="text-decoration: underline;">Chengyu Zhang</a> ||
        Powered by 
        <a href="https://gohugo.io/" style="text-decoration: underline;">Hugo</a> & 
        <a href="https://themes.gohugo.io/themes/hugo-papermod/" style="text-decoration: underline;">PaperMod</a>
    </p>
</footer>
</body>

</html>
