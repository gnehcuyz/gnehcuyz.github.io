---
ShowToc: false
title: Membership Inference Attacks for Large Language Models
date: 2024-12-27
draft: false
summary: Uncovered privacy risks in LLMs through attacks, API development, and experiments.
math: true
---

## Description
- Conducted research on privacy vulnerabilities in large language models (LLMs) by implementing membership inference attacks to evaluate risks and disparities in privacy.

## Tech Stack
- Python, PyTorch, NumPy, Scikit-learn.

## Contributions
- Implemented several attack algorithms using PyTorch.
- Built APIs to streamline experimental workflows, facilitating efficient handling of datasets and models.
- Designed and conducted experiments to evaluate the reliability and disparities in attack outcomes.