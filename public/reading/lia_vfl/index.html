<!DOCTYPE html>
<html lang="en" dir="auto">

<head><script src="/PersonalBlog/livereload.js?mindelay=10&amp;v=2&amp;port=63681&amp;path=PersonalBlog/livereload" data-no-instant defer></script><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="noindex, nofollow">
<title>Chengyu Zhang</title>
<meta name="keywords" content="">
<meta name="description" content="Label Inference Attacks in Vertical Federated Learning (VFL)
Introduction
Vertical Federated Learning (VFL) is a collaborative machine learning paradigm where two or more parties jointly train a model while holding complementary features for the same set of users. This enables organizations to collaborate on machine learning tasks without directly sharing their raw data, preserving privacy and adhering to regulations.
However, VFL is not without vulnerabilities. One of the significant concerns is label inference attacks. These attacks aim to deduce sensitive label information held by one party (usually the label holder) by exploiting the shared intermediate computations or gradients during the training process. In this blog post, we delve into the mechanics of label inference attacks, their implications, and potential countermeasures.">
<meta name="author" content="">
<link rel="canonical" href="http://localhost:63681/PersonalBlog/reading/lia_vfl/">
<link crossorigin="anonymous" href="/PersonalBlog/assets/css/stylesheet.45e028aa8ce0961349adf411b013ee39406be2c0bc80d4ea3fc04555f7f4611a.css" integrity="sha256-ReAoqozglhNJrfQRsBPuOUBr4sC8gNTqP8BFVff0YRo=" rel="preload stylesheet" as="style">

<link rel="icon" href="http://localhost:63681/PersonalBlog/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="http://localhost:63681/PersonalBlog/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="http://localhost:63681/PersonalBlog/favicon-32x32.png">
<link rel="apple-touch-icon" href="http://localhost:63681/PersonalBlog/apple-touch-icon.png">
<link rel="mask-icon" href="http://localhost:63681/PersonalBlog/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="http://localhost:63681/PersonalBlog/reading/lia_vfl/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="http://localhost:63681/PersonalBlog/" accesskey="h" title="Chengyu Zhang (Alt + H)">Chengyu Zhang</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="http://localhost:63681/PersonalBlog/research/" title="Research">
                    <span>Research</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:63681/PersonalBlog/projects/" title="Projects">
                    <span>Projects</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:63681/PersonalBlog/posts/" title="Blog">
                    <span>Blog</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:63681/PersonalBlog/reading/" title="Reading">
                    <span>Reading</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:63681/PersonalBlog/about/" title="About">
                    <span>About</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    
    <h1 class="post-title entry-hint-parent">
      
    </h1>
    <div class="post-meta">

</div>
  </header> 
  <div class="post-content"><h1 id="label-inference-attacks-in-vertical-federated-learning-vfl">Label Inference Attacks in Vertical Federated Learning (VFL)<a hidden class="anchor" aria-hidden="true" href="#label-inference-attacks-in-vertical-federated-learning-vfl">#</a></h1>
<h2 id="introduction">Introduction<a hidden class="anchor" aria-hidden="true" href="#introduction">#</a></h2>
<p>Vertical Federated Learning (VFL) is a collaborative machine learning paradigm where two or more parties jointly train a model while holding complementary features for the same set of users. This enables organizations to collaborate on machine learning tasks without directly sharing their raw data, preserving privacy and adhering to regulations.</p>
<p>However, VFL is not without vulnerabilities. One of the significant concerns is <strong>label inference attacks</strong>. These attacks aim to deduce sensitive label information held by one party (usually the label holder) by exploiting the shared intermediate computations or gradients during the training process. In this blog post, we delve into the mechanics of label inference attacks, their implications, and potential countermeasures.</p>
<hr>
<h2 id="understanding-label-inference-attacks">Understanding Label Inference Attacks<a hidden class="anchor" aria-hidden="true" href="#understanding-label-inference-attacks">#</a></h2>
<h3 id="what-are-label-inference-attacks">What Are Label Inference Attacks?<a hidden class="anchor" aria-hidden="true" href="#what-are-label-inference-attacks">#</a></h3>
<p>Label inference attacks are a type of adversarial attack where an attacker attempts to infer the ground-truth labels of a dataset in a VFL setting. This is particularly concerning in scenarios where labels are highly sensitive, such as health diagnoses or financial risk assessments.</p>
<h3 id="how-do-they-work">How Do They Work?<a hidden class="anchor" aria-hidden="true" href="#how-do-they-work">#</a></h3>
<h4 id="a-daily-life-example-the-bank-collaboration">A Daily-Life Example: The Bank Collaboration<a hidden class="anchor" aria-hidden="true" href="#a-daily-life-example-the-bank-collaboration">#</a></h4>
<p>Imagine a bank and an insurance company working together using VFL. The bank has customers&rsquo; financial data (like account balances and transaction histories), while the insurance company has the customers&rsquo; insurance claim statuses (labels). They aim to train a model to predict the likelihood of future claims while keeping their raw data private.</p>
<p>During this collaboration:</p>
<ul>
<li>The bank shares intermediate computations (like embeddings) based on its financial data.</li>
<li>The insurance company shares gradients influenced by the claim statuses (labels).</li>
</ul>
<p>An attacker, posing as a collaborator, analyzes the shared gradients. Since these gradients are directly influenced by the sensitive labels (e.g., whether a claim was approved), the attacker can reverse-engineer the gradients to guess the claim statuses. This is a label inference attack.</p>
<hr>
<h4 id="example-attack-mechanism">Example Attack Mechanism:<a hidden class="anchor" aria-hidden="true" href="#example-attack-mechanism">#</a></h4>
<p>In a typical VFL setup:</p>
<ol>
<li><strong>Feature Holder</strong>: Possesses the feature data.</li>
<li><strong>Label Holder</strong>: Possesses the sensitive labels.</li>
<li><strong>Coordinator</strong>: Manages the training process and aggregates intermediate results.</li>
</ol>
<p>During training, parties exchange intermediate outputs (e.g., embeddings or gradients) to jointly optimize the model. An adversary (either an internal participant or an external attacker) can analyze these exchanged data points to infer sensitive label information.</p>
<h4 id="example-attack-mechanism-1">Example Attack Mechanism:<a hidden class="anchor" aria-hidden="true" href="#example-attack-mechanism-1">#</a></h4>
<ul>
<li>By analyzing the gradient information:
<ul>
<li>Gradients are directly influenced by the label values.</li>
<li>By reverse-engineering or statistically analyzing the gradients, attackers can approximate or fully infer the labels.</li>
</ul>
</li>
<li>By observing embedding changes over iterations:
<ul>
<li>Embeddings can leak patterns correlated with labels, especially if they are not well-obfuscated.</li>
</ul>
</li>
</ul>
<hr>
<h2 id="implications-of-label-inference-attacks">Implications of Label Inference Attacks<a hidden class="anchor" aria-hidden="true" href="#implications-of-label-inference-attacks">#</a></h2>
<h3 id="privacy-breaches">Privacy Breaches<a hidden class="anchor" aria-hidden="true" href="#privacy-breaches">#</a></h3>
<p>The primary risk is the leakage of sensitive information. For example:</p>
<ul>
<li>In a healthcare VFL scenario, patient diagnoses could be inferred.</li>
<li>In financial collaborations, credit ratings or loan approval outcomes could be exposed.</li>
</ul>
<h3 id="loss-of-trust">Loss of Trust<a hidden class="anchor" aria-hidden="true" href="#loss-of-trust">#</a></h3>
<p>Organizations participating in federated learning may lose trust in the system, leading to reduced collaboration and limiting the adoption of federated learning frameworks.</p>
<h3 id="legal-and-compliance-issues">Legal and Compliance Issues<a hidden class="anchor" aria-hidden="true" href="#legal-and-compliance-issues">#</a></h3>
<p>Leaking sensitive information may result in violations of privacy laws like GDPR or HIPAA, leading to severe legal and financial repercussions.</p>
<hr>
<h2 id="defense-mechanisms">Defense Mechanisms<a hidden class="anchor" aria-hidden="true" href="#defense-mechanisms">#</a></h2>
<h3 id="gradient-perturbation">Gradient Perturbation<a hidden class="anchor" aria-hidden="true" href="#gradient-perturbation">#</a></h3>
<p>Adding noise to gradients before sharing them can obscure sensitive information, making it harder for attackers to reverse-engineer labels.</p>
<ul>
<li><strong>Advantages</strong>: Straightforward and effective.</li>
<li><strong>Disadvantages</strong>: May degrade model accuracy.</li>
</ul>
<h3 id="homomorphic-encryption">Homomorphic Encryption<a hidden class="anchor" aria-hidden="true" href="#homomorphic-encryption">#</a></h3>
<p>Using encryption techniques to encrypt gradients and embeddings ensures that attackers cannot directly access the underlying information.</p>
<ul>
<li><strong>Advantages</strong>: High level of security.</li>
<li><strong>Disadvantages</strong>: High computational overhead.</li>
</ul>
<h3 id="differential-privacy">Differential Privacy<a hidden class="anchor" aria-hidden="true" href="#differential-privacy">#</a></h3>
<p>Incorporating differential privacy mechanisms into the training process adds noise to the shared data, limiting the amount of information an attacker can glean.</p>
<ul>
<li><strong>Advantages</strong>: Provides formal privacy guarantees.</li>
<li><strong>Disadvantages</strong>: May require careful tuning to balance privacy and utility.</li>
</ul>
<h3 id="secure-multi-party-computation-smpc">Secure Multi-Party Computation (SMPC)<a hidden class="anchor" aria-hidden="true" href="#secure-multi-party-computation-smpc">#</a></h3>
<p>SMPC ensures that computations on shared data occur without revealing the underlying data to any party.</p>
<ul>
<li><strong>Advantages</strong>: Strong privacy protection.</li>
<li><strong>Disadvantages</strong>: Computationally expensive.</li>
</ul>
<h3 id="label-encryption">Label Encryption<a hidden class="anchor" aria-hidden="true" href="#label-encryption">#</a></h3>
<p>Encrypting labels before training prevents attackers from directly accessing sensitive information during the exchange process.</p>
<ul>
<li><strong>Advantages</strong>: Simple and direct.</li>
<li><strong>Disadvantages</strong>: May require protocol adjustments.</li>
</ul>
<hr>
<h2 id="future-directions">Future Directions<a hidden class="anchor" aria-hidden="true" href="#future-directions">#</a></h2>
<p>As federated learning becomes more prevalent, addressing privacy concerns like label inference attacks will be critical for its sustainable adoption. Potential research directions include:</p>
<ul>
<li><strong>Developing Lightweight Defenses</strong>: Focus on methods with minimal computational overhead.</li>
<li><strong>Improving Privacy-Utility Trade-offs</strong>: Balancing model performance and privacy preservation.</li>
<li><strong>Adversarial Robustness</strong>: Designing VFL systems that are inherently resistant to adversarial attacks.</li>
</ul>
<hr>
<h2 id="conclusion">Conclusion<a hidden class="anchor" aria-hidden="true" href="#conclusion">#</a></h2>
<p>Label inference attacks in Vertical Federated Learning highlight the dual-edged nature of collaborative learning. While VFL offers a promising avenue for secure and private machine learning, its vulnerabilities must be addressed through robust defenses. By implementing and iterating on privacy-preserving techniques, we can build a more secure federated learning ecosystem that benefits all stakeholders.</p>
<hr>
<p><strong>Have thoughts or questions? Share them in the comments below!</strong></p>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
    </ul>
  </footer>
</article>
    </main>
    
<footer class="footer">
        <span>&copy; 2025 <a href="http://localhost:63681/PersonalBlog/">Chengyu Zhang</a></span> · 

    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
</body>

</html>
